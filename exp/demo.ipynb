{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src/')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from netgan.netgan import *\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from netgan import utils\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import time\n",
    "from net.utils import *\n",
    "import net.net as net\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting 1 largest connected components\n"
     ]
    }
   ],
   "source": [
    "_A_obs, _X_obs, _z_obs = utils.load_npz('../data/cora_ml.npz')\n",
    "_A_obs = _A_obs + _A_obs.T\n",
    "_A_obs[_A_obs > 1] = 1\n",
    "lcc = utils.largest_connected_components(_A_obs)\n",
    "_A_obs = _A_obs[lcc,:][:,lcc]\n",
    "_N = _A_obs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_share = 0.1\n",
    "test_share = 0.05\n",
    "seed = 481516234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate the edges into train, test, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ones, val_ones, val_zeros, test_ones, test_zeros = utils.train_val_test_split_adjacency(_A_obs, val_share, test_share, seed, undirected=True, connected=True, asserts=True)\n",
    "\n",
    "train_graph = sp.coo_matrix((np.ones(len(train_ones)),(train_ones[:,0], train_ones[:,1]))).tocsr()\n",
    "assert (train_graph.toarray() == train_graph.toarray().T).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw_len = 16\n",
    "batch_size = 128\n",
    "mixing_coeff = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "walker = utils.RandomWalker(train_graph, rw_len, p=1, q=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2810"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_graph.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create our Net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "netmodel = net.Net(N=_N,\n",
    "                   H=24,\n",
    "                   affine=True,\n",
    "                   loss_fn=torch.nn.functional.cross_entropy,\n",
    "                   loggers=[net.GraphStatisticsLogger(train_graph, val_ones, val_zeros,\n",
    "                                                      mixing_coeff=mixing_coeff, log_every=50),\n",
    "                            net.BasicPrintLogger(print_every=100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 99, Loss: 4.69243\n",
      "Step: 199, Loss: 2.62516\n"
     ]
    }
   ],
   "source": [
    "netmodel.train(generator=net_walker(walker),\n",
    "               steps=300,\n",
    "               optimizer_fn=torch.optim.Adam,\n",
    "               optimizer_args={'lr': 0.01})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create model and train with stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netmodel = net.Net(N=_N,\n",
    "#                    H=15,\n",
    "#                    affine=False,\n",
    "#                    loss_fn=torch.nn.functional.cross_entropy,\n",
    "#                    stoppers=[net.OverlapStopper(train_graph, \n",
    "#                                                 mixing_coeff=mixing_coeff,\n",
    "#                                                 test_every=50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netmodel.train(generator=net_walker(walker),\n",
    "#                steps=200,\n",
    "#                optimizer_fn=torch.optim.Adam,\n",
    "#                optimizer_args={'lr': 0.01},\n",
    "#                EO_criterion=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build score matrix from trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_matrix = netmodel(torch.arange(start=0,end=_N, dtype=int))\n",
    "\n",
    "scores_matrix = scores_matrix_from_transition_matrix(transition_matrix=transition_matrix,\n",
    "                                                     symmetric=True,\n",
    "                                                     mixing_coeff=mixing_coeff)\n",
    "scores_matrix = sp.csr_matrix(scores_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate generalization via link prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.concatenate((np.ones(len(test_ones)), np.zeros(len(test_zeros))))\n",
    "test_scores = np.concatenate((scores_matrix[tuple(test_ones.T)].A1, scores_matrix[tuple(test_zeros.T)].A1))\n",
    "\n",
    "print(roc_auc_score(test_labels, test_scores))\n",
    "print(average_precision_score(test_labels, test_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build graph and evaluate graph statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_graph = utils.graph_from_scores(scores_matrix, train_graph.sum())\n",
    "\n",
    "plt.spy(sampled_graph, markersize=.2)\n",
    "plt.show()\n",
    "\n",
    "print(utils.edge_overlap(train_graph.toarray(), sampled_graph)/train_graph.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_sampled = utils.compute_graph_statistics(sampled_graph)\n",
    "statistics_train = utils.compute_graph_statistics(train_graph.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([statistics_train, statistics_sampled], index=['CORA-ML', 'Our method'])\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    new_row = [f'{round(x, 4):,}' for x in list(row)]\n",
    "    df.loc[index] = new_row\n",
    "\n",
    "df[['d_max', 'assortativity', 'triangle_count', \n",
    "    'wedge_count', 'claw_count', 'power_law_exp', \n",
    "    'clustering_coefficient', 'rel_edge_distr_entropy', \n",
    "    'LCC', 'gini', 'cpl']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot graph statistics over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "relevant_keys = ['d_max', 'wedge_count', 'claw_count', 'triangle_count', 'square_count',\n",
    "                 'power_law_exp', 'gini', 'rel_edge_distr_entropy', 'assortativity', 'clustering_coefficient',\n",
    "                 'cpl', 'overlap']\n",
    "\n",
    "relevant_keys = ['d_max', 'assortativity', 'triangle_count', 'power_law_exp', 'LCC', 'overlap']\n",
    "\n",
    "netmodel.loggers[0].print_statistics(keys=relevant_keys, EO_criterion=0.52, max_patience_for_VAL=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
