{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src/')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "import torch\n",
    "\n",
    "import utils\n",
    "from net import start_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_A_obs = load_npz('../data/datasets/CORA-ML.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_share = 0.1\n",
    "test_share = 0.05\n",
    "seed = 481516234\n",
    "\n",
    "train_ones, val_ones, val_zeros, test_ones, test_zeros = utils.train_val_test_split_adjacency(_A_obs, val_share, test_share, seed, undirected=True, connected=True, asserts=False)\n",
    "\n",
    "train_graph = sp.csr_matrix((np.ones(len(train_ones)),(train_ones[:,0], train_ones[:,1])))\n",
    "assert (train_graph.toarray() == train_graph.toarray().T).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "def train_val_test_split(A, val_share, test_share, seed=123):\n",
    "    \"\"\"\n",
    "    Split the edges of the input graph in training-, validation-, and test set.\n",
    "    \n",
    "    Randomly split a share of the edges of the input graph for validation- and test set, while ensuring that the \n",
    "    remaining graph stays connected. Additionally choose an equal amount of non-edges from the input graph.\n",
    "\n",
    "    Args:\n",
    "        A (sp.csr.csr_matrix): The input adjacency matrix.\n",
    "        val_share: Fraction of edges that form the validation set.\n",
    "        test_share: Fraction of edges that form the test set.\n",
    "        seed: Random seed.\n",
    "        \n",
    "    Returns:\n",
    "        train_graph (sp.csr.csr_matrix): Remaining graph after split, which is used for training.\n",
    "        val_ones (np.array): Validation edges. Rows represent indices of the input adjacency matrix with value 1. \n",
    "        val_zeros (np.array): Validation non-edges. Rows represent indices of the input adjacency matrix with value 0.\n",
    "        test_ones (np.array): Test edges. Rows represent indices of the input adjacency matrix with value 1. \n",
    "        test_zeros (np.array): Test non-edges. Rows represent indices of the input adjacency matrix with value 0.\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    G = nx.from_scipy_sparse_matrix(A)\n",
    "    num_nodes = G.number_of_nodes()\n",
    "    num_edges = G.number_of_edges()\n",
    "\n",
    "    # Test symmetric, connected and has sufficiently many edges\n",
    "    assert (abs(A - A.T) > 1e-10).nnz == 0, \"Graph is not symmetric.\"\n",
    "    assert nx.is_connected(G), \"Graph is not connected.\"\n",
    "    assert (\n",
    "        num_edges - num_nodes > (val_share + test_share) * num_edges + 1\n",
    "    ), \"Val- and test-share are too large.\"\n",
    "\n",
    "    # Ensure that train graph is symmetric by protecting certain edges\n",
    "    # Split edges into val-, test- and training-set\n",
    "    protected_edges = list(nx.minimum_spanning_tree(G).edges())\n",
    "    edges_set = set(G.edges())\n",
    "    free_edges = list(edges_set - set(protected_edges))\n",
    "    np.random.shuffle(free_edges)\n",
    "    num_val = int(val_share * num_edges)\n",
    "    num_test = int(test_share * num_edges)\n",
    "    val_ones = np.array(free_edges[:num_val])\n",
    "    test_ones = np.array(free_edges[num_val : num_val + num_test])\n",
    "    train_edges = free_edges[num_val + num_test :] + protected_edges\n",
    "\n",
    "    G_train = nx.Graph()\n",
    "    G_train.add_nodes_from(G)\n",
    "    G_train.add_edges_from(train_edges)\n",
    "    train_graph = nx.to_scipy_sparse_matrix(G_train, dtype=np.float)\n",
    "\n",
    "    # Draw non-edges from input graph: draw random tuples, remove direction, loops, and input edges\n",
    "    non_edges = np.random.choice(num_nodes, size=(2 * (num_val + num_test), 2))\n",
    "    non_edges = np.sort(\n",
    "        non_edges[non_edges[:, 0] != non_edges[:, 1]]\n",
    "    )  # Remove loops and direction\n",
    "    non_edges = np.unique(non_edges, axis=0)  # Remove multiple edges\n",
    "    non_edges = [\n",
    "        tuple(edge) for edge in non_edges if tuple(edge) not in edges_set\n",
    "    ]  # Remove input edges\n",
    "    np.random.shuffle(non_edges)\n",
    "    assert len(non_edges) >= num_val + num_test, \"Too few non-zero edges.\"\n",
    "    val_zeros = np.array(non_edges[:num_val])\n",
    "    test_zeros = np.array(non_edges[num_val : num_val + num_test])\n",
    "    return train_graph, val_ones, val_zeros, test_ones, test_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graph, val_ones, val_zeros, test_ones, test_zeros = train_val_test_split(A=_A_obs, val_share=val_share, test_share=test_share, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_statistics import max_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191\n",
      "201\n",
      "198\n",
      "208\n",
      "200\n",
      "198\n",
      "204\n",
      "195\n",
      "194\n",
      "199\n",
      "209\n",
      "201\n",
      "196\n",
      "202\n",
      "200\n",
      "196\n",
      "193\n",
      "195\n",
      "205\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "for seed in range(20):\n",
    "    train_graph, val_ones, val_zeros, test_ones, test_zeros = train_val_test_split(A=_A_obs, val_share=val_share, test_share=test_share, seed=seed)\n",
    "    print(max_degree(train_graph))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
