{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src/')\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import save_npz, load_npz, csr_matrix\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import utils\n",
    "import graph_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation(object):\n",
    "    \n",
    "    def __init__(self, experiment_root, statistic_fns):\n",
    "        self.experiment_root = experiment_root\n",
    "        self.statistic_fns = statistic_fns    \n",
    "    \n",
    "    def _load_timings(self):\n",
    "        return self._load('timing')\n",
    "    \n",
    "    def _load_overlaps(self):\n",
    "        return self._load('overlap')\n",
    "    \n",
    "    def _load_roc_aucs(self):\n",
    "        return self._load('ROC-AUC')\n",
    "    \n",
    "    def _load_avg_precs(self):\n",
    "        return self._load('avg_prec')\n",
    "    \n",
    "    def _load(self, name):\n",
    "        \n",
    "        def get_filename(idx):\n",
    "            filename = os.path.join(self.experiment_root,\n",
    "                                    f'Experiment_{idx:0{self.str_exp_len}d}',\n",
    "                                    'sampled_graphs',\n",
    "                                    f'{name}.pickle')\n",
    "            return filename\n",
    "        \n",
    "        dicts = [utils.load_dict(get_filename(idx)) for idx in range(self.num_experiments)]\n",
    "        return dicts\n",
    "    \n",
    "    def compute_statistics(self):\n",
    "        # parse experiment root folder\n",
    "        experiment_keys = [key for key in os.listdir(self.experiment_root) if key[:11]=='Experiment_']\n",
    "        self.num_experiments = len(experiment_keys)\n",
    "        self.str_exp_len = len(str(self.num_experiments))\n",
    "        \n",
    "        # load overlaps and timings\n",
    "        overlaps = self._load_overlaps()\n",
    "        roc_aucs = self._load_roc_aucs()\n",
    "        avg_precs = self._load_avg_precs()\n",
    "        timings = self._load_timings()\n",
    "        \n",
    "        steps = max(timings[0].keys())\n",
    "        step_len = len(str(steps))\n",
    "        step_idxs = len(timings[0].keys())\n",
    "        invoke_every = steps // step_idxs\n",
    "        \n",
    "        statistics = {name: np.zeros([self.num_experiments,\n",
    "                                      step_idxs]) for name in self.statistic_fns.keys()}\n",
    "        statistics['Edge Overlap (%)'] = np.zeros([self.num_experiments, step_idxs])\n",
    "        statistics['ROC-AUC Score'] = np.zeros([self.num_experiments, step_idxs])\n",
    "        statistics['Average Precision'] = np.zeros([self.num_experiments, step_idxs])\n",
    "        statistics['Time (s)'] = np.zeros([self.num_experiments, step_idxs])\n",
    "                    \n",
    "        for step_idx, step in enumerate(range(invoke_every, steps+invoke_every, invoke_every)):\n",
    "            for experiment in range(self.num_experiments):\n",
    "                # load sparse graph\n",
    "                graph_name = f'graph_{step:0{step_len}d}.npz'\n",
    "                graph_path = os.path.join(self.experiment_root,\n",
    "                                          f'Experiment_{experiment:0{self.str_exp_len}d}',\n",
    "                                          'sampled_graphs',\n",
    "                                          graph_name)\n",
    "                graph = load_npz(graph_path)\n",
    "                # compute statistics\n",
    "                statistics['Edge Overlap (%)'][experiment, step_idx] = overlaps[experiment][step]\n",
    "                statistics['ROC-AUC Score'][experiment, step_idx] = roc_aucs[experiment][step]\n",
    "                statistics['Average Precision'][experiment, step_idx] = avg_precs[experiment][step]\n",
    "                statistics['Time (s)'][experiment, step_idx] = timings[experiment][step]\n",
    "                for name, statistic_fn in self.statistic_fns.items():\n",
    "                    statistics[name][experiment, step_idx] = statistic_fn(graph)\n",
    "\n",
    "                    \n",
    "        self.statistics = statistics\n",
    "        self.steps = steps\n",
    "        self.invoke_every = invoke_every\n",
    "\n",
    "    def aggregate_statistics(self, num_bins, start=0, end=1):\n",
    "        # binning\n",
    "        overlaps = self.statistics['Edge Overlap (%)']\n",
    "        lin = np.linspace(start, end, num_bins+1)\n",
    "        statistics_mean = {name:np.zeros(num_bins) for name in self.statistics.keys()}\n",
    "        statistics_std = {name:np.zeros(num_bins) for name in self.statistics.keys()}\n",
    "        for idx, (start, end) in enumerate(zip(lin[:-1], lin[1:])):\n",
    "            args = np.argwhere(np.logical_and(start<overlaps, overlaps<=end))\n",
    "            for name, statistic in self.statistics.items():\n",
    "                statistics_mean[name][idx] = statistic[args[:,0], args[:,1]].mean()\n",
    "                statistics_std[name][idx] = statistic[args[:,0], args[:,1]].std()\n",
    "        \n",
    "        self.statistics_mean = statistics_mean\n",
    "        self.statistics_std = statistics_std\n",
    "        self.mean_std = (statistics_mean, statistics_std)\n",
    "                \n",
    "    def export_statistics(self):\n",
    "        pass\n",
    "    \n",
    "    def plot_statistics(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ours = Evaluation(experiment_root='../logs/CORA-ML/Ours/',\n",
    "                       statistic_fns={#'Assortativity':graph_statistics.assortativity,\n",
    "                                      #'Average Degree':graph_statistics.average_degree,\n",
    "                                      'Claw Count':graph_statistics.claw_count,\n",
    "                                      #'Clustering Coefficient':graph_statistics.clustering_coefficient,\n",
    "                                      #'Characteristic Path Length':graph_statistics.compute_cpl,\n",
    "                                      #'Edge Distribution Entropy':graph_statistics.edge_distribution_entropy,\n",
    "                                      #'Gini':graph_statistics.gini,\n",
    "                                      #'LCC Size':graph_statistics.LCC,\n",
    "                                      #'Max Degree':graph_statistics.max_degree,\n",
    "                                      #'Min Degree':graph_statistics.min_degree,\n",
    "                                      #'Num Connected Components':graph_statistics.num_connected_components,\n",
    "                                      #'Power Law α':graph_statistics.power_law_alpha,\n",
    "                                      #'Spectral Gap':graph_statistics.spectral_gap,\n",
    "                                      'Square Count':graph_statistics.square_count,\n",
    "                                      #'Triangle Count':graph_statistics.triangle_count,\n",
    "                                      'Wedge Count':graph_statistics.wedge_count,\n",
    "                                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eval_ours.compute_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ours.aggregate_statistics(num_bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00442282, 0.09479581, 0.34542238, 0.45717234, 0.55889724,\n",
       "       0.61831048, 0.66637181, 0.71384343, 0.73979065, 0.76146248,\n",
       "       0.79006339, 0.80967124, 0.81866431, 0.83384933, 0.84357954,\n",
       "       0.85330974, 0.86171311, 0.8708536 , 0.8799941 , 0.88235294])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_ours.statistics['Edge Overlap (%)'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forge Adjacency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_fa = Evaluation(experiment_root='../logs/CORA-ML/baseline_FA/',\n",
    "                     statistic_fns={#'Assortativity':graph_statistics.assortativity,\n",
    "                                    #'Average Degree':graph_statistics.average_degree,\n",
    "                                    'Claw Count':graph_statistics.claw_count,\n",
    "                                    #'Clustering Coefficient':graph_statistics.clustering_coefficient,\n",
    "                                    #'Characteristic Path Length':graph_statistics.compute_cpl,\n",
    "                                    #'Edge Distribution Entropy':graph_statistics.edge_distribution_entropy,\n",
    "                                    #'Gini':graph_statistics.gini,\n",
    "                                    #'LCC Size':graph_statistics.LCC,\n",
    "                                    #'Max Degree':graph_statistics.max_degree,\n",
    "                                    #'Min Degree':graph_statistics.min_degree,\n",
    "                                    #'Num Connected Components':graph_statistics.num_connected_components,\n",
    "                                    #'Power Law α':graph_statistics.power_law_alpha,\n",
    "                                    #'Spectral Gap':graph_statistics.spectral_gap,\n",
    "                                    'Square Count':graph_statistics.square_count,\n",
    "                                    #'Triangle Count':graph_statistics.triangle_count,\n",
    "                                    'Wedge Count':graph_statistics.wedge_count,\n",
    "                                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_fa.compute_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_fa.aggregate_statistics(num_bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Claw Count': array([[481830.],\n",
       "        [593270.],\n",
       "        [332699.],\n",
       "        [422081.],\n",
       "        [550518.],\n",
       "        [500513.],\n",
       "        [446634.],\n",
       "        [495019.],\n",
       "        [525607.],\n",
       "        [515139.],\n",
       "        [658976.],\n",
       "        [407958.],\n",
       "        [495019.],\n",
       "        [516567.],\n",
       "        [444974.],\n",
       "        [510862.],\n",
       "        [468463.],\n",
       "        [559511.],\n",
       "        [447798.],\n",
       "        [469087.]]), 'Square Count': array([[1039.],\n",
       "        [1188.],\n",
       "        [ 973.],\n",
       "        [ 965.],\n",
       "        [1162.],\n",
       "        [1229.],\n",
       "        [1075.],\n",
       "        [1029.],\n",
       "        [ 944.],\n",
       "        [1217.],\n",
       "        [1158.],\n",
       "        [ 948.],\n",
       "        [1127.],\n",
       "        [1042.],\n",
       "        [1012.],\n",
       "        [1273.],\n",
       "        [1121.],\n",
       "        [1174.],\n",
       "        [1094.],\n",
       "        [1158.]]), 'Wedge Count': array([[47801.],\n",
       "        [50226.],\n",
       "        [45017.],\n",
       "        [47001.],\n",
       "        [49019.],\n",
       "        [48823.],\n",
       "        [47206.],\n",
       "        [47950.],\n",
       "        [48139.],\n",
       "        [49023.],\n",
       "        [50598.],\n",
       "        [46539.],\n",
       "        [48327.],\n",
       "        [48302.],\n",
       "        [47365.],\n",
       "        [49421.],\n",
       "        [47444.],\n",
       "        [49597.],\n",
       "        [48304.],\n",
       "        [48504.]]), 'Edge Overlap (%)': array([[0.51909185],\n",
       "        [0.53530886],\n",
       "        [0.52705293],\n",
       "        [0.51953413],\n",
       "        [0.5285272 ],\n",
       "        [0.52985405],\n",
       "        [0.51968156],\n",
       "        [0.5220404 ],\n",
       "        [0.51157305],\n",
       "        [0.53545629],\n",
       "        [0.52970662],\n",
       "        [0.51555359],\n",
       "        [0.52233525],\n",
       "        [0.52587351],\n",
       "        [0.5226301 ],\n",
       "        [0.52351467],\n",
       "        [0.52351467],\n",
       "        [0.53324488],\n",
       "        [0.52896948],\n",
       "        [0.5252838 ]]), 'ROC-AUC Score': array([[0.5645332],\n",
       "        [0.5645332],\n",
       "        [0.5645332],\n",
       "        [0.5645332],\n",
       "        [0.5645332],\n",
       "        [0.5645332],\n",
       "        [0.5645332],\n",
       "        [0.5645332],\n",
       "        [0.5645332],\n",
       "        [0.5645332],\n",
       "        [0.5645332],\n",
       "        [0.5645332],\n",
       "        [0.5645332],\n",
       "        [0.5645332],\n",
       "        [0.5645332],\n",
       "        [0.5645332],\n",
       "        [0.5645332],\n",
       "        [0.5645332],\n",
       "        [0.5645332],\n",
       "        [0.5645332]]), 'Average Precision': array([[0.65970984],\n",
       "        [0.65970984],\n",
       "        [0.65970984],\n",
       "        [0.65970984],\n",
       "        [0.65970984],\n",
       "        [0.65970984],\n",
       "        [0.65970984],\n",
       "        [0.65970984],\n",
       "        [0.65970984],\n",
       "        [0.65970984],\n",
       "        [0.65970984],\n",
       "        [0.65970984],\n",
       "        [0.65970984],\n",
       "        [0.65970984],\n",
       "        [0.65970984],\n",
       "        [0.65970984],\n",
       "        [0.65970984],\n",
       "        [0.65970984],\n",
       "        [0.65970984],\n",
       "        [0.65970984]]), 'Time (s)': array([[2.07177854],\n",
       "        [2.1288414 ],\n",
       "        [2.07788467],\n",
       "        [2.14007878],\n",
       "        [2.09979916],\n",
       "        [2.07782674],\n",
       "        [2.0842948 ],\n",
       "        [2.06141734],\n",
       "        [2.0789609 ],\n",
       "        [2.03374505],\n",
       "        [2.05246592],\n",
       "        [2.0421555 ],\n",
       "        [2.06933522],\n",
       "        [2.03174043],\n",
       "        [2.06100774],\n",
       "        [2.04619694],\n",
       "        [2.04133534],\n",
       "        [2.0397265 ],\n",
       "        [2.06264329],\n",
       "        [2.20814824]])}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_fa.statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forge transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ft = Evaluation(experiment_root='../logs/CORA-ML/baseline_FT/',\n",
    "                     statistic_fns={#'Assortativity':graph_statistics.assortativity,\n",
    "                                    #'Average Degree':graph_statistics.average_degree,\n",
    "                                    'Claw Count':graph_statistics.claw_count,\n",
    "                                    #'Clustering Coefficient':graph_statistics.clustering_coefficient,\n",
    "                                    #'Characteristic Path Length':graph_statistics.compute_cpl,\n",
    "                                    #'Edge Distribution Entropy':graph_statistics.edge_distribution_entropy,\n",
    "                                    #'Gini':graph_statistics.gini,\n",
    "                                    #'LCC Size':graph_statistics.LCC,\n",
    "                                    #'Max Degree':graph_statistics.max_degree,\n",
    "                                    #'Min Degree':graph_statistics.min_degree,\n",
    "                                    #'Num Connected Components':graph_statistics.num_connected_components,\n",
    "                                    #'Power Law α':graph_statistics.power_law_alpha,\n",
    "                                    #'Spectral Gap':graph_statistics.spectral_gap,\n",
    "                                    'Square Count':graph_statistics.square_count,\n",
    "                                    #'Triangle Count':graph_statistics.triangle_count,\n",
    "                                    'Wedge Count':graph_statistics.wedge_count,\n",
    "                                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ft.compute_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ft.aggregate_statistics(num_bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabular_from_statistics(EO_criterion, statistics):\n",
    "    tabular_mean = {}\n",
    "    tabular_std = {}\n",
    "    for model_name, (statistics_mean, statistics_std) in statistics.items():\n",
    "        tabular_mean[model_name] = {}\n",
    "        tabular_std[model_name] = {}\n",
    "        # find matching EO\n",
    "        overlap = statistics_mean['Edge Overlap (%)']\n",
    "        try:\n",
    "            arg = np.argwhere(overlap>EO_criterion).min()\n",
    "        except:\n",
    "            raise Exception(f'Max Edge Overlap of {model_name} is {np.nan_to_num(overlap, -1).max():.3f}')\n",
    "        for statistic_name in statistics_mean.keys():\n",
    "            tabular_mean[model_name][statistic_name] = statistics_mean[statistic_name][arg]\n",
    "            tabular_std[model_name][statistic_name] = statistics_std[statistic_name][arg]\n",
    "    return (tabular_mean, tabular_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular = tabular_from_statistics(EO_criterion=0.5,\n",
    "                                  statistics={'ours': eval_ours.mean_std})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'ours': {'Claw Count': 1738945.6,\n",
       "   'Square Count': 6755.95,\n",
       "   'Wedge Count': 81647.35,\n",
       "   'Edge Overlap (%)': 0.550656051894442,\n",
       "   'ROC-AUC Score': 0.9250405933379817,\n",
       "   'Average Precision': 0.9334074743225752,\n",
       "   'Time (s)': 14.25318933725357}},\n",
       " {'ours': {'Claw Count': 238717.88288907052,\n",
       "   'Square Count': 505.7745026194974,\n",
       "   'Wedge Count': 2806.073667511243,\n",
       "   'Edge Overlap (%)': 0.008070070940608833,\n",
       "   'ROC-AUC Score': 0.004968024675141033,\n",
       "   'Average Precision': 0.00499826370837697,\n",
       "   'Time (s)': 0.17529627872599637}})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tabular = tabular_from_statistics(0.5, {\n",
    "    'fa':eval_fa.mean_std, \n",
    "    'ft':eval_ft.mean_std,\n",
    "    'ours': eval_ours.mean_std,\n",
    "                                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def df_from_tabular(tabular, keys=None):\n",
    "    mean_dicts, std_dicts = tabular\n",
    "    string_tabular = {}\n",
    "    for (model_key, mean_dict) in mean_dicts.items():\n",
    "        std_dict = std_dicts[model_key]\n",
    "        string_tabular[model_key] = {}\n",
    "        for (statistc_key, mean) in mean_dict.items():\n",
    "            std = std_dict[statistc_key]\n",
    "            string_tabular[model_key][statistc_key] = (f'{mean:.3f} \\u00B1 {std:.3f}')\n",
    "    df = pd.DataFrame(string_tabular.values(), string_tabular.keys())\n",
    "    if keys is not None:\n",
    "        df = df[keys]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_from_tabular(tabular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claw Count</th>\n",
       "      <th>Square Count</th>\n",
       "      <th>Wedge Count</th>\n",
       "      <th>Edge Overlap (%)</th>\n",
       "      <th>ROC-AUC Score</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fa</th>\n",
       "      <td>492126.250 ± 68398.655</td>\n",
       "      <td>1096.400 ± 96.770</td>\n",
       "      <td>48230.300 ± 1264.029</td>\n",
       "      <td>0.525 ± 0.006</td>\n",
       "      <td>0.565 ± 0.000</td>\n",
       "      <td>0.660 ± 0.000</td>\n",
       "      <td>2.075 ± 0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ft</th>\n",
       "      <td>725638.550 ± 79992.302</td>\n",
       "      <td>1564.600 ± 80.837</td>\n",
       "      <td>57510.000 ± 1158.362</td>\n",
       "      <td>0.561 ± 0.005</td>\n",
       "      <td>0.706 ± 0.000</td>\n",
       "      <td>0.793 ± 0.000</td>\n",
       "      <td>1.940 ± 0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ours</th>\n",
       "      <td>1738945.600 ± 238717.883</td>\n",
       "      <td>6755.950 ± 505.775</td>\n",
       "      <td>81647.350 ± 2806.074</td>\n",
       "      <td>0.551 ± 0.008</td>\n",
       "      <td>0.925 ± 0.005</td>\n",
       "      <td>0.933 ± 0.005</td>\n",
       "      <td>14.253 ± 0.175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Claw Count        Square Count           Wedge Count  \\\n",
       "fa      492126.250 ± 68398.655   1096.400 ± 96.770  48230.300 ± 1264.029   \n",
       "ft      725638.550 ± 79992.302   1564.600 ± 80.837  57510.000 ± 1158.362   \n",
       "ours  1738945.600 ± 238717.883  6755.950 ± 505.775  81647.350 ± 2806.074   \n",
       "\n",
       "     Edge Overlap (%)  ROC-AUC Score Average Precision        Time (s)  \n",
       "fa      0.525 ± 0.006  0.565 ± 0.000     0.660 ± 0.000   2.075 ± 0.042  \n",
       "ft      0.561 ± 0.005  0.706 ± 0.000     0.793 ± 0.000   1.940 ± 0.044  \n",
       "ours    0.551 ± 0.008  0.925 ± 0.005     0.933 ± 0.005  14.253 ± 0.175  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "print('a\\nb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%\n"
     ]
    }
   ],
   "source": [
    "print('%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load_npz in module scipy.sparse._matrix_io:\n",
      "\n",
      "load_npz(file)\n",
      "    Load a sparse matrix from a file using ``.npz`` format.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    file : str or file-like object\n",
      "        Either the file name (string) or an open file (file-like object)\n",
      "        where the data will be loaded.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    result : csc_matrix, csr_matrix, bsr_matrix, dia_matrix or coo_matrix\n",
      "        A sparse matrix containing the loaded data.\n",
      "    \n",
      "    Raises\n",
      "    ------\n",
      "    IOError\n",
      "        If the input file does not exist or cannot be read.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    scipy.sparse.save_npz: Save a sparse matrix to a file using ``.npz`` format.\n",
      "    numpy.load: Load several arrays from a ``.npz`` archive.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Store sparse matrix to disk, and load it again:\n",
      "    \n",
      "    >>> import scipy.sparse\n",
      "    >>> sparse_matrix = scipy.sparse.csc_matrix(np.array([[0, 0, 3], [4, 0, 0]]))\n",
      "    >>> sparse_matrix\n",
      "    <2x3 sparse matrix of type '<class 'numpy.int64'>'\n",
      "       with 2 stored elements in Compressed Sparse Column format>\n",
      "    >>> sparse_matrix.todense()\n",
      "    matrix([[0, 0, 3],\n",
      "            [4, 0, 0]], dtype=int64)\n",
      "    \n",
      "    >>> scipy.sparse.save_npz('/tmp/sparse_matrix.npz', sparse_matrix)\n",
      "    >>> sparse_matrix = scipy.sparse.load_npz('/tmp/sparse_matrix.npz')\n",
      "    \n",
      "    >>> sparse_matrix\n",
      "    <2x3 sparse matrix of type '<class 'numpy.int64'>'\n",
      "        with 2 stored elements in Compressed Sparse Column format>\n",
      "    >>> sparse_matrix.todense()\n",
      "    matrix([[0, 0, 3],\n",
      "            [4, 0, 0]], dtype=int64)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(load_npz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = {1:'a', 2:'b', 5:'e'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(dct.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones([3,3]) > 0#np.zeros([3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros([3,3])\n",
    "0<a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True],\n",
       "       [ True,  True,  True],\n",
       "       [ True,  True,  True]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a<=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logical_and(0<a, a<=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[np.argwhere(np.logical_and(0<a, a<=1))[:,0],np.argwhere(np.logical_and(0<a, a<=1))[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['graph_090.npz',\n",
       " 'graph_080.npz',\n",
       " 'graph_100.npz',\n",
       " 'overlap.pickle',\n",
       " 'graph_060.npz',\n",
       " 'graph_015.npz',\n",
       " 'graph_075.npz',\n",
       " 'graph_005.npz',\n",
       " 'graph_020.npz',\n",
       " 'graph_070.npz',\n",
       " 'graph_065.npz',\n",
       " 'graph_010.npz',\n",
       " 'graph_040.npz',\n",
       " 'graph_095.npz',\n",
       " 'graph_050.npz',\n",
       " 'graph_035.npz',\n",
       " 'timing.pickle',\n",
       " 'graph_025.npz',\n",
       " 'graph_085.npz',\n",
       " 'graph_055.npz',\n",
       " 'graph_045.npz',\n",
       " 'graph_030.npz']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../logs/experiments_CORA-ML/Experiment_0/sampled_graphs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing(f):\n",
    "    def g(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        y = f(*args, **kwargs)\n",
    "        g.last_time = time.time() - start\n",
    "        return y\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing\n",
    "def loop(iters):\n",
    "    x = 0\n",
    "    for i in range(iters):\n",
    "        x += i\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3828277587890625e-05"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loop(100)\n",
    "loop.last_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(*args, **kwargs):\n",
    "    y = 0\n",
    "    for x in args:\n",
    "        y += x\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = [1,2,3,4,5,6]\n",
    "f(*lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(lst[0], lst[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:netgan]",
   "language": "python",
   "name": "conda-env-netgan-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
