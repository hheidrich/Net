{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import eigs\n",
    "\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from scipy.sparse.csgraph import connected_components, minimum_spanning_tree\n",
    "from scipy.sparse.linalg import eigs\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "import igraph\n",
    "import powerlaw\n",
    "from numba import jit\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../src/')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#'import tensorflow as tf\n",
    "import torch\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import time\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "# from netgan.netgan import *\n",
    "# from netgan import utils\n",
    "\n",
    "from net.utils import *\n",
    "from net import utils_netgan as utils\n",
    "import net.net as net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting 1 largest connected components\n"
     ]
    }
   ],
   "source": [
    "_A_obs, _X_obs, _z_obs = utils.load_npz('../data/cora_ml.npz')\n",
    "_A_obs = _A_obs + _A_obs.T\n",
    "_A_obs[_A_obs > 1] = 1\n",
    "lcc = utils.largest_connected_components(_A_obs)\n",
    "_A_obs = _A_obs[lcc,:][:,lcc]\n",
    "_N = _A_obs.shape[0]\n",
    "\n",
    "val_share = 0.1\n",
    "test_share = 0.05\n",
    "seed = 481516234\n",
    "\n",
    "train_ones, val_ones, val_zeros, test_ones, test_zeros = utils.train_val_test_split_adjacency(_A_obs, val_share, test_share, seed, undirected=True, connected=True, asserts=True)\n",
    "\n",
    "train_graph = sp.coo_matrix((np.ones(len(train_ones)),(train_ones[:,0], train_ones[:,1]))).tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_overlap(A, B):\n",
    "    \"\"\"\n",
    "    Compute edge overlap between input graphs A and B, i.e. how many edges in A are also present in graph B. Assumes\n",
    "    that both graphs contain the same number of edges.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A: sparse matrix or np.array of shape (N,N).\n",
    "       First input adjacency matrix.\n",
    "    B: sparse matrix or np.array of shape (N,N).\n",
    "       Second input adjacency matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float, the edge overlap.\n",
    "    \"\"\"\n",
    "\n",
    "    return ((A == B) & (A == 1)).sum()\n",
    "\n",
    "def squares(g):\n",
    "    \"\"\"\n",
    "    Count the number of squares for each node\n",
    "    Parameters\n",
    "    ----------\n",
    "    g: igraph Graph object\n",
    "       The input graph.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List with N entries (N is number of nodes) that give the number of squares a node is part of.\n",
    "    \"\"\"\n",
    "\n",
    "    cliques = g.cliques(min=4, max=4)\n",
    "    result = [0] * g.vcount()\n",
    "    for i, j, k, l in cliques:\n",
    "        result[i] += 1\n",
    "        result[j] += 1\n",
    "        result[k] += 1\n",
    "        result[l] += 1\n",
    "    return result\n",
    "\n",
    "def statistics_degrees(A_in):\n",
    "    \"\"\"\n",
    "    Compute min, max, mean degree\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A_in: sparse matrix or np.array\n",
    "          The input adjacency matrix.\n",
    "    Returns\n",
    "    -------\n",
    "    d_max. d_min, d_mean\n",
    "    \"\"\"\n",
    "\n",
    "    degrees = A_in.sum(axis=0)\n",
    "    return np.max(degrees), np.min(degrees), np.mean(degrees)\n",
    "\n",
    "\n",
    "def statistics_LCC(A_in):\n",
    "    \"\"\"\n",
    "    Compute the size of the largest connected component (LCC)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A_in: sparse matrix or np.array\n",
    "          The input adjacency matrix.\n",
    "    Returns\n",
    "    -------\n",
    "    Size of LCC\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    unique, counts = np.unique(connected_components(A_in)[1], return_counts=True)\n",
    "    LCC = np.where(connected_components(A_in)[1] == np.argmax(counts))[0]\n",
    "    return LCC\n",
    "\n",
    "\n",
    "def statistics_wedge_count(A_in):\n",
    "    \"\"\"\n",
    "    Compute the wedge count of the input graph\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A_in: sparse matrix or np.array\n",
    "          The input adjacency matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The wedge count.\n",
    "    \"\"\"\n",
    "\n",
    "    degrees = A_in.sum(axis=0)\n",
    "    return float(np.sum(np.array([0.5 * x * (x - 1) for x in degrees])))\n",
    "\n",
    "\n",
    "def statistics_claw_count(A_in):\n",
    "    \"\"\"\n",
    "    Compute the claw count of the input graph\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A_in: sparse matrix or np.array\n",
    "          The input adjacency matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Claw count\n",
    "    \"\"\"\n",
    "\n",
    "    degrees = A_in.sum(axis=0)\n",
    "    return float(np.sum(np.array([1 / 6. * x * (x - 1) * (x - 2) for x in degrees])))\n",
    "\n",
    "\n",
    "def statistics_triangle_count(A_in):\n",
    "    \"\"\"\n",
    "    Compute the triangle count of the input graph\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A_in: sparse matrix or np.array\n",
    "          The input adjacency matrix.\n",
    "    Returns\n",
    "    -------\n",
    "    Triangle count\n",
    "    \"\"\"\n",
    "\n",
    "    A_graph = nx.from_numpy_matrix(A_in)\n",
    "    triangles = nx.triangles(A_graph)\n",
    "    t = np.sum(list(triangles.values())) / 3\n",
    "    return int(t)\n",
    "\n",
    "\n",
    "def statistics_square_count(A_in):\n",
    "    \"\"\"\n",
    "    Compute the square count of the input graph\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A_in: sparse matrix or np.array\n",
    "          The input adjacency matrix.\n",
    "    Returns\n",
    "    -------\n",
    "    Square count\n",
    "    \"\"\"\n",
    "\n",
    "    A_igraph = igraph.Graph.Adjacency((A_in > 0).tolist()).as_undirected()\n",
    "    return int(np.sum(squares(A_igraph)) / 4)\n",
    "\n",
    "\n",
    "def statistics_power_law_alpha(A_in):\n",
    "    \"\"\"\n",
    "    Compute the power law coefficient of the degree distribution of the input graph\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A_in: sparse matrix or np.array\n",
    "          The input adjacency matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Power law coefficient\n",
    "    \"\"\"\n",
    "\n",
    "    degrees = A_in.sum(axis=0)\n",
    "    return powerlaw.Fit(degrees, xmin=max(np.min(degrees),1), verbose=False).power_law.alpha\n",
    "\n",
    "\n",
    "def statistics_gini(A_in):\n",
    "    \"\"\"\n",
    "    Compute the Gini coefficient of the degree distribution of the input graph\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A_in: sparse matrix or np.array\n",
    "          The input adjacency matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Gini coefficient\n",
    "    \"\"\"\n",
    "\n",
    "    n = A_in.shape[0]\n",
    "    degrees = A_in.sum(axis=0)\n",
    "    degrees_sorted = np.sort(degrees)\n",
    "    G = (2 * np.sum(np.array([i * degrees_sorted[i] for i in range(len(degrees))]))) / (n * np.sum(degrees)) - (\n",
    "                                                                                                               n + 1) / n\n",
    "    return float(G)\n",
    "\n",
    "\n",
    "def statistics_edge_distribution_entropy(A_in):\n",
    "    \"\"\"\n",
    "    Compute the relative edge distribution entropy of the input graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A_in: sparse matrix or np.array\n",
    "          The input adjacency matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Rel. edge distribution entropy\n",
    "    \"\"\"\n",
    "\n",
    "    degrees = A_in.sum(axis=0)\n",
    "    m = 0.5 * np.sum(np.square(A_in))\n",
    "    n = A_in.shape[0]\n",
    "\n",
    "    H_er = 1 / np.log(n) * np.sum(-degrees / (2 * float(m)) * np.log((degrees+.0001) / (2 * float(m))))\n",
    "    return H_er\n",
    "\n",
    "def statistics_cluster_props(A, Z_obs):\n",
    "    def get_blocks(A_in, Z_obs, normalize=True):\n",
    "        block = Z_obs.T.dot(A_in.dot(Z_obs))\n",
    "        counts = np.sum(Z_obs, axis=0)\n",
    "        blocks_outer = counts[:,None].dot(counts[None,:])\n",
    "        if normalize:\n",
    "            blocks_outer = np.multiply(block, 1/blocks_outer)\n",
    "        return blocks_outer\n",
    "    \n",
    "    in_blocks = get_blocks(A, Z_obs)\n",
    "    diag_mean = np.multiply(in_blocks, np.eye(in_blocks.shape[0])).mean()\n",
    "    offdiag_mean = np.multiply(in_blocks, 1-np.eye(in_blocks.shape[0])).mean() \n",
    "    return diag_mean, offdiag_mean\n",
    "\n",
    "def statistics_compute_cpl(A):\n",
    "    \"\"\"Compute characteristic path length.\"\"\"\n",
    "    P = sp.csgraph.shortest_path(sp.csr_matrix(A))\n",
    "    return P[((1 - np.isinf(P)) * (1 - np.eye(P.shape[0]))).astype(np.bool)].mean()\n",
    "\n",
    "def statistics_smallest_eigvals_of_LCC(A):\n",
    "    \"\"\"Computes few smallest eigenvalues of graph Laplacian, restricted to largest connected component.\"\"\"\n",
    "    G = nx.from_numpy_matrix(A)\n",
    "    Gc = G.subgraph(max(nx.connected_components(G), key=len))\n",
    "    L = nx.normalized_laplacian_matrix(Gc)\n",
    "    vals, vecs = eigs(L, k=2, sigma=-0.0001)\n",
    "    return np.real(vals)\n",
    "\n",
    "\n",
    "def compute_graph_statistics(A_in, Z_obs=None):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A_in: sparse matrix\n",
    "          The input adjacency matrix.\n",
    "    Z_obs: np.matrix [N, K], where K is the number of classes.\n",
    "          Matrix whose rows are one-hot vectors indicating the class membership of the respective node.\n",
    "          \n",
    "    Returns\n",
    "    -------\n",
    "    Dictionary containing the following statistics:\n",
    "             * Maximum, minimum, mean degree of nodes\n",
    "             * Size of the largest connected component (LCC)\n",
    "             * Wedge count\n",
    "             * Claw count\n",
    "             * Triangle count\n",
    "             * Square count\n",
    "             * Power law exponent\n",
    "             * Gini coefficient\n",
    "             * Relative edge distribution entropy\n",
    "             * Assortativity\n",
    "             * Clustering coefficient\n",
    "             * Number of connected components\n",
    "             * Intra- and inter-community density (if Z_obs is passed)\n",
    "             * Characteristic path length\n",
    "    \"\"\"\n",
    "\n",
    "    A = A_in.copy()\n",
    "\n",
    "    assert ((A == A.T).all())\n",
    "    A_graph = nx.from_numpy_matrix(A).to_undirected()\n",
    "\n",
    "    statistics = {}\n",
    "\n",
    "    d_max, d_min, d_mean = statistics_degrees(A)\n",
    "\n",
    "    # Degree statistics\n",
    "    statistics['d_max'] = d_max\n",
    "    statistics['d_min'] = d_min\n",
    "    statistics['d'] = d_mean\n",
    "\n",
    "    # largest connected component\n",
    "    LCC = statistics_LCC(A)\n",
    "\n",
    "    statistics['LCC'] = LCC.shape[0]\n",
    "    # wedge count\n",
    "    statistics['wedge_count'] = statistics_wedge_count(A)\n",
    "\n",
    "    # claw count\n",
    "    statistics['claw_count'] = statistics_claw_count(A)\n",
    "\n",
    "    # triangle count\n",
    "    statistics['triangle_count'] = statistics_triangle_count(A)\n",
    "\n",
    "    # Square count\n",
    "    statistics['square_count'] = statistics_square_count(A)\n",
    "    # power law exponent\n",
    "    statistics['power_law_exp'] = statistics_power_law_alpha(A)\n",
    "    # gini coefficient\n",
    "    statistics['gini'] = statistics_gini(A)\n",
    "    # Relative edge distribution entropy\n",
    "    statistics['rel_edge_distr_entropy'] = statistics_edge_distribution_entropy(A)\n",
    "    # Assortativity\n",
    "    statistics['assortativity'] = nx.degree_assortativity_coefficient(A_graph)\n",
    "    # Clustering coefficient\n",
    "    statistics['clustering_coefficient'] = 3 * statistics['triangle_count'] / statistics['claw_count']    \n",
    "    # Number of connected components\n",
    "    statistics['n_components'] = connected_components(A)[0]\n",
    "    if Z_obs is not None:\n",
    "        # inter- and intra-community density\n",
    "        intra, inter = statistics_cluster_props(A, Z_obs)\n",
    "        statistics['intra_community_density'] = intra\n",
    "        statistics['inter_community_density'] = inter\n",
    "    statistics['cpl'] = statistics_compute_cpl(A)\n",
    "    # Spectral gap of largest connected component\n",
    "    eigvals = statistics_smallest_eigvals_of_LCC(A)\n",
    "    statistics['spectral_gap'] = eigvals[1] - eigvals[0]\n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_val_performance(scores_matrix, val_ones, val_zeros):\n",
    "    \"\"\" Compute the ROC-AUC score and average precision of a graph (link prediction performance).\"\"\"\n",
    "    edge_scores = np.append(scores_matrix[tuple(val_ones.T)].A1, \n",
    "                            scores_matrix[tuple(val_zeros.T)].A1)\n",
    "    actual_labels_val = np.append(np.ones(len(val_ones)), np.zeros(len(val_zeros)))\n",
    "    \n",
    "    roc_auc = roc_auc_score(actual_labels_val, edge_scores)\n",
    "    avg_prec = average_precision_score(actual_labels_val, edge_scores)\n",
    "    return roc_auc, avg_prec\n",
    "\n",
    "def s_edge_overlap(A, B):\n",
    "    \"\"\"\n",
    "    Compute edge overlap between input graphs A and B, i.e. how many edges in A are also present in graph B. Assumes\n",
    "    that both graphs contain the same number of edges.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A: sparse matrix or np.array of shape (N,N).\n",
    "       First input adjacency matrix.\n",
    "    B: sparse matrix or np.array of shape (N,N).\n",
    "       Second input adjacency matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float, the edge overlap.\n",
    "    \"\"\"\n",
    "\n",
    "    return A.multiply(B).sum() / 2\n",
    "\n",
    "\n",
    "def s_statistics_max_degree(A_in):\n",
    "    \"\"\"Compute max degree.\"\"\"\n",
    "    degrees = A_in.sum(axis=-1)\n",
    "    return np.max(degrees)\n",
    "\n",
    "def s_statistics_min_degree(A_in):\n",
    "    \"\"\"Compute min degree.\"\"\"\n",
    "    degrees = A_in.sum(axis=-1)\n",
    "    return np.min(degrees)\n",
    "\n",
    "def s_statistics_average_degree(A_in):\n",
    "    \"\"\"Compute average degree.\"\"\"\n",
    "    degrees = A_in.sum(axis=-1)\n",
    "    return np.mean(degrees)\n",
    "\n",
    "\n",
    "def s_statistics_LCC(A_in):\n",
    "    \"\"\"\n",
    "    Compute the size of the largest connected component (LCC)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A_in: sparse matrix or np.array\n",
    "          The input adjacency matrix.\n",
    "    Returns\n",
    "    -------\n",
    "    Size of LCC\n",
    "\n",
    "    \"\"\"\n",
    "    G = nx.from_scipy_sparse_matrix(A_in)\n",
    "    return max([len(c) for c in nx.connected_components(G)])\n",
    "\n",
    "def s_statistics_num_connected_components(A_in):\n",
    "    \"\"\"Compute the number of connected components.\"\"\"\n",
    "    G = nx.from_scipy_sparse_matrix(A_in)\n",
    "    return len(list(nx.connected_components(G)))\n",
    "\n",
    "\n",
    "def s_statistics_wedge_count(A_in):\n",
    "    \"\"\"\n",
    "    Compute the wedge count of the input graph\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A_in: sparse matrix or np.array\n",
    "          The input adjacency matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The wedge count.\n",
    "    \"\"\"\n",
    "\n",
    "    degrees = np.array(A_in.sum(axis=-1))\n",
    "    return 0.5 * np.dot(degrees.T, degrees-1).reshape([])\n",
    "\n",
    "\n",
    "def s_statistics_claw_count(A_in):\n",
    "    \"\"\"\n",
    "    Compute the claw count of the input graph\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A_in: sparse matrix or np.array\n",
    "          The input adjacency matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Claw count\n",
    "    \"\"\"\n",
    "\n",
    "    degrees = np.array(A_in.sum(axis=-1))\n",
    "    return 1/6 * np.sum(degrees * (degrees-1) * (degrees-2))\n",
    "\n",
    "\n",
    "def s_statistics_triangle_count(A_in):\n",
    "    \"\"\"\n",
    "    Compute the triangle count of the input graph\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A_in: sparse matrix or np.array\n",
    "          The input adjacency matrix.\n",
    "    Returns\n",
    "    -------\n",
    "    Triangle count\n",
    "    \"\"\"\n",
    "\n",
    "    A_graph = nx.from_scipy_sparse_matrix(A_in)\n",
    "    triangles = nx.triangles(A_graph)\n",
    "    t = np.sum(list(triangles.values())) / 3\n",
    "    return int(t)\n",
    "\n",
    "\n",
    "def s_statistics_square_count(A_in):\n",
    "    \"\"\"\n",
    "    Compute the square count of the input graph\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A_in: sparse matrix or np.array\n",
    "          The input adjacency matrix.\n",
    "    Returns\n",
    "    -------\n",
    "    Square count\n",
    "    \"\"\"\n",
    "\n",
    "    A_squared = A_in @ A_in\n",
    "    common_neighbors = sp.triu(A_squared, k=1).tocsr()\n",
    "    num_common_neighbors = np.array(common_neighbors[common_neighbors.nonzero()]).reshape(-1)\n",
    "    return np.dot(num_common_neighbors, num_common_neighbors-1) / 4\n",
    "\n",
    "\n",
    "def s_statistics_power_law_alpha(A_in):\n",
    "    \"\"\"\n",
    "    Compute the power law coefficient of the degree distribution of the input graph\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A_in: sparse matrix or np.array\n",
    "          The input adjacency matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Power law coefficient\n",
    "    \"\"\"\n",
    "\n",
    "    degrees = np.array(A_in.sum(axis=-1)).flatten()\n",
    "    return powerlaw.Fit(degrees, xmin=max(np.min(degrees),1), verbose=False).power_law.alpha\n",
    "\n",
    "\n",
    "def s_statistics_gini(A_in):\n",
    "    \"\"\"\n",
    "    Compute the Gini coefficient of the degree distribution of the input graph\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A_in: sparse matrix or np.array\n",
    "          The input adjacency matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Gini coefficient\n",
    "    \"\"\"\n",
    "    N = A_in.shape[0]\n",
    "    degrees_sorted = np.sort(np.array(A_in.sum(axis=-1)).flatten())\n",
    "    return 2 * np.dot(degrees_sorted, np.arange(1, N+1)) / (N * np.sum(degrees_sorted)) - (N+1) / N\n",
    "\n",
    "\n",
    "def s_statistics_edge_distribution_entropy(A_in):\n",
    "    \"\"\"\n",
    "    Compute the relative edge distribution entropy of the input graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A_in: sparse matrix or np.array\n",
    "          The input adjacency matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Rel. edge distribution entropy\n",
    "    \"\"\"\n",
    "    N = A_in.shape[0]\n",
    "    degrees = np.array(A_in.sum(axis=-1)).flatten()\n",
    "    degrees /= degrees.sum()\n",
    "    return -np.dot(np.log(degrees), degrees) / np.log(N)\n",
    "\n",
    "\n",
    "def s_statistics_compute_cpl(A_in):\n",
    "    \"\"\"Compute characteristic path length.\"\"\"\n",
    "    P = sp.csgraph.shortest_path(A_in)\n",
    "    return P[((1 - np.isinf(P)) * (1 - np.eye(P.shape[0]))).astype(np.bool)].mean()\n",
    "\n",
    "def s_statistics_smallest_eigvals_of_LCC(A):\n",
    "    \"\"\"Computes few smallest eigenvalues of graph Laplacian, restricted to largest connected component.\"\"\"\n",
    "    G = nx.from_scipy_sparse_matrix(A)\n",
    "    Gc = G.subgraph(max(nx.connected_components(G), key=len))\n",
    "    L = nx.normalized_laplacian_matrix(Gc)\n",
    "    vals, vecs = eigs(L, k=2, sigma=-0.0001)\n",
    "    return np.real(vals)\n",
    "\n",
    "def s_statistics_spectral_gap(A_in):\n",
    "    \"\"\" Compute spectral gap.\"\"\"\n",
    "    eigvals = s_statistics_smallest_eigvals_of_LCC(A_in)\n",
    "    return eigvals[1] - eigvals[0]\n",
    "\n",
    "def s_statistics_assortativity(A_in):\n",
    "    \"\"\"Compute assortativity.\"\"\"\n",
    "    G = nx.from_scipy_sparse_matrix(A_in)\n",
    "    return nx.degree_assortativity_coefficient(G)\n",
    "\n",
    "def s_statistics_clustering_coefficient(A_in):\n",
    "    \"\"\"Compute clustering coefficient.\"\"\"\n",
    "    return 3 * s_statistics_triangle_count(A_in) / s_statistics_claw_count(A_in)\n",
    "\n",
    "\n",
    "def s_compute_graph_statistics(A):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A_in: sparse matrix\n",
    "          The input adjacency matrix.\n",
    "          \n",
    "    Returns\n",
    "    -------\n",
    "    Dictionary containing the following statistics:\n",
    "             * Maximum, minimum, mean degree of nodes\n",
    "             * Size of the largest connected component (LCC)\n",
    "             * Wedge count\n",
    "             * Claw count\n",
    "             * Triangle count\n",
    "             * Square count\n",
    "             * Power law exponent\n",
    "             * Gini coefficient\n",
    "             * Relative edge distribution entropy\n",
    "             * Assortativity\n",
    "             * Clustering coefficient\n",
    "             * Number of connected components\n",
    "             * Intra- and inter-community density (if Z_obs is passed)\n",
    "             * Characteristic path length\n",
    "    \"\"\"\n",
    "\n",
    "    statistics = {}\n",
    "\n",
    "    # Degree statistics\n",
    "    statistics['d_max'] = s_statistics_max_degree(A)\n",
    "    statistics['d_min'] = s_statistics_min_degree(A)\n",
    "    statistics['d'] = s_statistics_average_degree(A)\n",
    "    # largest connected component\n",
    "    statistics['LCC'] = s_statistics_LCC(A)\n",
    "    # wedge count\n",
    "    statistics['wedge_count'] = s_statistics_wedge_count(A)\n",
    "    # claw count\n",
    "    statistics['claw_count'] = s_statistics_claw_count(A)\n",
    "    # triangle count\n",
    "    statistics['triangle_count'] = s_statistics_triangle_count(A)\n",
    "    # Square count\n",
    "    statistics['square_count'] = s_statistics_square_count(A)\n",
    "    # power law exponent\n",
    "    statistics['power_law_exp'] = s_statistics_power_law_alpha(A)\n",
    "    # gini coefficient\n",
    "    statistics['gini'] = s_statistics_gini(A)\n",
    "    # Relative edge distribution entropy\n",
    "    statistics['rel_edge_distr_entropy'] = s_statistics_edge_distribution_entropy(A)\n",
    "    # Assortativity\n",
    "    statistics['assortativity'] = s_statistics_assortativity(A)\n",
    "    # Clustering coefficient\n",
    "    statistics['clustering_coefficient'] = s_statistics_clustering_coefficient(A)\n",
    "    # Number of connected components\n",
    "    statistics['n_components'] = s_statistics_num_connected_components(A)\n",
    "    # Characteristic path length\n",
    "    statistics['cpl'] = s_statistics_compute_cpl(A)\n",
    "    # Spectral gap of largest connected component\n",
    "    statistics['spectral_gap'] = s_statistics_spectral_gap(A)\n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configuration_model(A, B=None, EO=None):\n",
    "    \"\"\"Given two graphs A and B with same amount of edges, generates new graph by keeping overlapping edges,\n",
    "       and rewiring remaining edges such that degrees of nodes in A are preserved. Self-loops and multiple \n",
    "       edges are removed. If B is None, draws the percentage EO of edges from A.\"\"\"\n",
    "    configuration_graph = np.zeros_like(A)\n",
    "    if B is not None:\n",
    "        configuration_graph = A * B\n",
    "    else:\n",
    "        B = np.triu(A, k=1)\n",
    "        B /= B.sum()\n",
    "        nonzero_ixs = B.nonzero()\n",
    "        edges_from_A = np.random.choice(a=len(nonzero_ixs[0]), size=int(EO * A.sum() / 2), replace=False, \n",
    "                                        p=B[nonzero_ixs])\n",
    "        configuration_graph[nonzero_ixs[0][edges_from_A], nonzero_ixs[1][edges_from_A]] = 1\n",
    "        configuration_graph = configuration_graph + configuration_graph.T\n",
    "    degrees = (A.sum(axis=-1) - configuration_graph.sum(axis=-1)).astype(int)\n",
    "    stubs = np.zeros(degrees.sum())\n",
    "    counter = 0\n",
    "    for i in degrees.nonzero()[0]:\n",
    "        stubs[counter: counter+degrees[i]] = i * np.ones(degrees[i])\n",
    "        counter += degrees[i]\n",
    "    np.random.shuffle(stubs)\n",
    "    stubs = stubs.reshape(-1, 2).astype(int)\n",
    "    configuration_graph[stubs[:, 0], stubs[:, 1]] = 1\n",
    "    configuration_graph[stubs[:, 1], stubs[:, 0]] = 1  \n",
    "    np.fill_diagonal(configuration_graph, 0)\n",
    "    return configuration_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_wrapper(f, *args):\n",
    "    start = time.time()\n",
    "    print(f(*args))\n",
    "    print(time.time()-start)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = train_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = configuration_model(A.toarray(), EO=0.52)\n",
    "B = sp.csr_matrix(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'> <class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(A), type(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7096\n",
      "0.05903506278991699\n",
      "3548.0\n",
      "0.0008366107940673828\n"
     ]
    }
   ],
   "source": [
    "# Vanilla\n",
    "time_wrapper(edge_overlap, A.toarray(), B)\n",
    "\n",
    "# Sparse\n",
    "time_wrapper(s_edge_overlap, A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2802\n",
      "0.16067862510681152\n",
      "2802\n",
      "0.18396568298339844\n"
     ]
    }
   ],
   "source": [
    "# Vanilla\n",
    "time_wrapper(statistics_triangle_count, A.toarray())\n",
    "\n",
    "# Sparse\n",
    "time_wrapper(s_statistics_triangle_count, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(238.0, 1.0, 4.8277580071174375)\n",
      "0.016636133193969727\n",
      "(238.0, 1.0, 4.8277580071174375)\n",
      "0.0006220340728759766\n"
     ]
    }
   ],
   "source": [
    "# Vanilla\n",
    "time_wrapper(statistics_degrees, A.toarray())\n",
    "\n",
    "# Sparse\n",
    "time_wrapper(statistics_degrees, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101747.0\n",
      "0.017568111419677734\n",
      "101747.0\n",
      "0.001300811767578125\n"
     ]
    }
   ],
   "source": [
    "# Vanilla\n",
    "time_wrapper(statistics_wedge_count, A.toarray())\n",
    "\n",
    "# Sparse\n",
    "time_wrapper(s_statistics_wedge_count, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3033514.0\n",
      "0.022715091705322266\n",
      "3033514.0\n",
      "0.0005564689636230469\n"
     ]
    }
   ],
   "source": [
    "# Vanilla\n",
    "time_wrapper(statistics_claw_count, A.toarray())\n",
    "\n",
    "# Sparse\n",
    "time_wrapper(s_statistics_claw_count, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101747.0\n",
      "0.017568111419677734\n",
      "101747.0\n",
      "0.001300811767578125\n"
     ]
    }
   ],
   "source": [
    "# Vanilla\n",
    "time_wrapper(statistics_wedge_count, A.toarray())\n",
    "\n",
    "# Sparse\n",
    "time_wrapper(s_statistics_wedge_count, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457\n",
      "0.7692854404449463\n",
      "14269.0\n",
      "0.01426386833190918\n"
     ]
    }
   ],
   "source": [
    "# Vanilla\n",
    "time_wrapper(statistics_square_count, A.toarray())\n",
    "\n",
    "# Sparse\n",
    "time_wrapper(s_statistics_square_count, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test if square count is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "734486.0700000001"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expec = 0\n",
    "for i in range(100):\n",
    "    ER_graph = nx.erdos_renyi_graph(100, 0.5)\n",
    "    ER_graph = nx.to_scipy_sparse_matrix(ER_graph)\n",
    "    expec += s_statistics_square_count(ER_graph) / 100\n",
    "expec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61401.939999999995"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expec = 0\n",
    "for i in range(100):\n",
    "    ER_graph = nx.erdos_renyi_graph(100, 0.5)\n",
    "    ER_graph = nx.to_scipy_sparse_matrix(ER_graph)\n",
    "    expec += statistics_square_count(ER_graph.toarray()) / 100\n",
    "expec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected number of squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "735229.6875"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.special import binom\n",
    "\n",
    "binom(100, 4) * 3*2*1 / 2**5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected number of 4-cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61269.140625"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binom(100, 4) / 2 ** (binom(4, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation: we compute actual square count, but they compute 4-cliques count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ... 2807 2808 2809]\n",
      "0.4540128707885742\n",
      "2810\n",
      "0.2728407382965088\n"
     ]
    }
   ],
   "source": [
    "# Vanilla\n",
    "time_wrapper(statistics_LCC, A.toarray())\n",
    "\n",
    "# Sparse\n",
    "time_wrapper(s_statistics_LCC, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4818118959889852\n",
      "0.01648235321044922\n",
      "0.48252363976122714\n",
      "0.0006756782531738281\n"
     ]
    }
   ],
   "source": [
    "# Vanilla\n",
    "time_wrapper(statistics_gini, A.toarray())\n",
    "\n",
    "# Sparse\n",
    "time_wrapper(s_statistics_gini, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9406731398068211\n",
      "0.04870343208312988\n",
      "0.94067574800982\n",
      "0.0010118484497070312\n"
     ]
    }
   ],
   "source": [
    "# Vanilla\n",
    "time_wrapper(statistics_edge_distribution_entropy, A.toarray())\n",
    "\n",
    "# Sparse\n",
    "time_wrapper(s_statistics_edge_distribution_entropy, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.630006245811316\n",
      "3.6048834323883057\n",
      "5.630006245811316\n",
      "3.485039472579956\n"
     ]
    }
   ],
   "source": [
    "# Vanilla\n",
    "time_wrapper(statistics_compute_cpl, A.toarray())\n",
    "\n",
    "# Sparse\n",
    "time_wrapper(s_statistics_compute_cpl, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test all statistics at once (except edge overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d_max': 238.0, 'd_min': 1.0, 'd': 4.828113879003559, 'LCC': 2810, 'wedge_count': 101749.0, 'claw_count': 3033515.0, 'triangle_count': 2802, 'square_count': 457, 'power_law_exp': 1.854959374066405, 'gini': 0.4818118959889852, 'rel_edge_distr_entropy': 0.9406731398068211, 'assortativity': -0.07625760260188129, 'clustering_coefficient': 0.002771042833149004, 'n_components': 1, 'spectral_gap': 0.00611441079539339}\n",
      "1.9164848327636719\n",
      "{'d_max': 238.0, 'd_min': 1.0, 'd': 4.828113879003559, 'LCC': 2810, 'wedge_count': 101749.0, 'claw_count': 3033515.0, 'triangle_count': 2802, 'square_count': 14269.0, 'power_law_exp': 1.854959374066405, 'gini': 0.48252363976122714, 'rel_edge_distr_entropy': 0.94067574800982, 'assortativity': -0.07625760260188129, 'clustering_coefficient': 0.002771042833149004, 'n_components': 1, 'spectral_gap': 0.0061144107953933855}\n",
      "1.1001887321472168\n"
     ]
    }
   ],
   "source": [
    "# Vanilla\n",
    "time_wrapper(compute_graph_statistics, A.toarray())\n",
    "\n",
    "# Sparse\n",
    "time_wrapper(s_compute_graph_statistics, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC-AUC and average precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(s_val_performance(_A_obs, val_ones=val_ones, val_zeros=val_zeros))\n",
    "print(s_val_performance(train_graph, val_ones=val_ones, val_zeros=val_zeros))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
