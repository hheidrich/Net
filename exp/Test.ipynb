{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/holgerizor/anaconda3/envs/netgan/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/holgerizor/anaconda3/envs/netgan/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/holgerizor/anaconda3/envs/netgan/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/holgerizor/anaconda3/envs/netgan/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/holgerizor/anaconda3/envs/netgan/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/holgerizor/anaconda3/envs/netgan/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/holgerizor/anaconda3/envs/netgan/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/holgerizor/anaconda3/envs/netgan/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/holgerizor/anaconda3/envs/netgan/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/holgerizor/anaconda3/envs/netgan/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/holgerizor/anaconda3/envs/netgan/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/holgerizor/anaconda3/envs/netgan/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src/')\n",
    "\n",
    "import abc\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from net.net import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from netgan import netgan\n",
    "\n",
    "dtype = torch.float32\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ground_truth(p_stars, samples_per_class):\n",
    "    assert p_stars.ndim == 2\n",
    "    classes_in, classes_out = p_stars.shape\n",
    "    X = np.ndarray([classes_in, samples_per_class], dtype=np.int)\n",
    "    Y = np.ndarray([classes_in, samples_per_class], dtype=np.int)\n",
    "    for class_in in range(classes_in):\n",
    "        X[class_in] = class_in * np.ones([samples_per_class])\n",
    "        Y[class_in] = np.argmax(np.random.multinomial(n=1, pvals=p_stars[class_in],\n",
    "                                                      size=[samples_per_class]),\n",
    "                                axis=-1)\n",
    "    return np.eye(classes_out)[X.reshape([-1])], Y.reshape([-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = 20\n",
    "\"\"\"\n",
    "p_stars=np.array([[0.1, 0.1, 0.2, 0.2, 0.4],\n",
    "                  [0.5, 0.2, 0.1, 0.1, 0.1],\n",
    "                  [0.0, 0.3, 0.3, 0.3, 0.1],\n",
    "                  [0.2, 0.2, 0.2, 0.2, 0.2],\n",
    "                  [0.1, 0.0, 0.6, 0.0, 0.3]])\n",
    "\"\"\"\n",
    "p_stars = np.random.dirichlet(alpha=0.2*np.ones(n_nodes), size=n_nodes)\n",
    "\n",
    "X, Y = draw_ground_truth(p_stars=p_stars,\n",
    "                         samples_per_class=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "amounts = X.T @ np.eye(n_nodes)[Y]\n",
    "normalized = amounts/amounts.sum(axis=-1).reshape((n_nodes,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger(abc.ABC):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def log(self, step, loss):\n",
    "        pass\n",
    "    \n",
    "class BasicPrintLogger(Logger):\n",
    "    def __init__(self, print_every=100):\n",
    "        self.print_every = print_every\n",
    "    \n",
    "    def log(self, step, loss, x, logits, labels):\n",
    "        if step % self.print_every == self.print_every-1:\n",
    "                print(f'Step: {step}, Loss: {loss:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(object):\n",
    "    def __init__(self, N, H, loss_fn=torch.nn.functional.cross_entropy, logger=None):\n",
    "        self.loss_fn = loss_fn\n",
    "        self.logger = logger\n",
    "        self._optimizer = None\n",
    "        self.w_down = torch.tensor(0.1 * torch.randn(N, H, device=device, dtype=dtype), requires_grad=True)\n",
    "        self.w_up =  torch.tensor(0.1 * torch.randn(H, N, device=device, dtype=dtype), requires_grad=True)\n",
    "              \n",
    "    def __call__(self, x):\n",
    "        x = torch.tensor(x, dtype=dtype)\n",
    "        return torch.nn.functional.softmax(self.predict_logits(x),\n",
    "                                           dim=-1).detach().numpy()\n",
    "    \n",
    "    def predict_logits(self, x):\n",
    "        return (x @ self.w_down) @ self.w_up\n",
    "    \n",
    "    def _train_step(self, x, labels):\n",
    "        logits = self.predict_logits(x)\n",
    "        loss = self.loss_fn(logits, labels)\n",
    "        self._optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self._optimizer.step()\n",
    "        return logits, loss.item()\n",
    "        \n",
    "    def train(self, x, labels, steps, optimizer_fn, optimizer_args):\n",
    "        x = torch.tensor(x, dtype=dtype)\n",
    "        labels = torch.tensor(labels, dtype=torch.int64)\n",
    "        self._optimizer = optimizer_fn([self.w_down, self.w_up] ,**optimizer_args)\n",
    "        for step in range(steps):\n",
    "            logits, loss = self._train_step(x, labels)\n",
    "            if self.logger:\n",
    "                self.logger.log(step, loss, x, logits, labels)\n",
    "                \n",
    "    def train_generator(self, generator, steps, optimizer_fn, optimizer_args):\n",
    "        self._optimizer = optimizer_fn([self.w_down, self.w_up] ,**optimizer_args)\n",
    "        for step in range(steps):\n",
    "            x, labels = next(generator)\n",
    "            logits, loss = self._train_step(x, labels)\n",
    "            if self.logger:\n",
    "                self.logger.log(step, loss, x, logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_nodes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-479914060860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBasicPrintLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'n_nodes' is not defined"
     ]
    }
   ],
   "source": [
    "model = Net(N=n_nodes, H=5, loss_fn=torch.nn.CrossEntropyLoss(), logger=BasicPrintLogger(print_every=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "net.net.Net"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.7110e-04,  3.9167e-03,  1.0348e-03,  2.0983e-03, -3.7287e-03,\n",
       "          1.2352e-03,  4.6427e-03,  7.5704e-03,  1.9505e-03,  4.4851e-03,\n",
       "         -1.0603e-02,  3.5484e-03, -4.1915e-03,  1.5552e-02,  7.9632e-03,\n",
       "          1.0556e-02,  8.6400e-03, -4.4887e-03, -9.9381e-03, -4.3090e-03],\n",
       "        [-2.7796e-02, -2.1374e-03,  1.1913e-02, -2.2807e-05, -6.3665e-03,\n",
       "         -2.6748e-03, -1.1650e-03,  1.6857e-02, -1.2133e-02,  1.7140e-02,\n",
       "         -1.3890e-02, -2.4740e-02,  9.3011e-03, -1.9735e-02,  1.7850e-02,\n",
       "          7.0608e-03,  2.9447e-02, -3.5309e-02, -7.1110e-03, -4.6917e-04],\n",
       "        [ 2.5697e-02,  5.9656e-03, -3.3157e-02,  3.8982e-03,  2.1440e-02,\n",
       "          1.4393e-02,  1.0008e-02, -1.5717e-02,  1.4459e-02, -6.0308e-03,\n",
       "          4.8090e-03,  5.5262e-02, -3.4271e-02,  3.2733e-02, -2.9167e-02,\n",
       "          1.5600e-03, -2.6403e-02,  2.3320e-02, -1.8319e-03, -1.2062e-02],\n",
       "        [ 1.5873e-02, -2.9874e-03,  2.1740e-02,  2.5282e-03, -9.3776e-04,\n",
       "         -5.9209e-03, -7.3181e-03,  6.0164e-03,  4.2512e-03, -3.0059e-04,\n",
       "         -1.7981e-03, -7.4938e-03, -3.1144e-04, -2.0851e-03,  4.3831e-03,\n",
       "          1.7042e-02, -3.0934e-03, -2.2873e-03,  1.7922e-03,  7.7774e-03],\n",
       "        [ 1.1312e-02, -1.3381e-02,  8.1671e-02,  1.6339e-02, -3.0220e-03,\n",
       "         -3.7962e-02, -3.7662e-02,  3.9594e-02,  4.6136e-03,  2.2980e-02,\n",
       "         -1.6429e-02, -4.1199e-02,  6.6793e-03, -6.2611e-03,  1.8010e-02,\n",
       "          4.3609e-02,  1.9368e-02, -7.1406e-04,  1.0366e-02,  2.6826e-02],\n",
       "        [-2.2760e-02, -8.8783e-03,  2.1339e-02,  2.5552e-03, -4.6379e-03,\n",
       "         -2.3976e-02, -2.1903e-02,  5.0183e-03, -7.0488e-03,  3.7757e-03,\n",
       "          1.0340e-02, -3.1010e-02,  2.3617e-02, -1.7292e-02, -1.1326e-03,\n",
       "         -2.4459e-02,  5.9707e-03,  2.6252e-02,  2.0671e-02,  1.4384e-02],\n",
       "        [-3.4323e-02,  1.8107e-03,  1.7206e-02, -5.6376e-03, -3.9684e-02,\n",
       "         -2.5137e-02, -7.3247e-03,  5.6528e-03, -1.0555e-02, -1.1045e-02,\n",
       "          4.8677e-03, -5.5469e-02,  5.4776e-02,  7.3100e-03,  3.0367e-02,\n",
       "         -4.0667e-02,  1.9933e-02,  4.0619e-02,  5.3715e-03,  9.9239e-03],\n",
       "        [ 6.0383e-03, -2.1985e-03, -8.2115e-04, -9.9126e-03, -1.0985e-02,\n",
       "          7.1924e-04,  2.8830e-04, -1.7292e-02, -2.9256e-03, -2.1636e-02,\n",
       "          1.9383e-02, -1.8316e-02,  2.2251e-02, -2.0571e-02,  1.7189e-03,\n",
       "         -2.0453e-02, -1.6590e-02,  1.0274e-02,  1.0300e-02,  7.6393e-03],\n",
       "        [ 1.7333e-02, -1.3968e-02,  1.1740e-03,  1.0557e-02,  4.9400e-02,\n",
       "          4.4375e-03, -1.7747e-02, -3.2128e-03,  5.2113e-03,  1.9123e-02,\n",
       "          8.2462e-03,  3.7643e-02, -4.4968e-02, -3.3288e-02, -4.5033e-02,\n",
       "          2.1787e-02, -2.1264e-02, -2.0782e-02,  2.0185e-02,  4.5156e-03],\n",
       "        [-1.8390e-02,  2.5416e-03, -2.1850e-02, -4.3682e-03,  2.3178e-03,\n",
       "          1.2750e-02,  1.1529e-02, -3.3843e-03, -7.9584e-03,  4.7711e-03,\n",
       "         -3.0641e-03,  4.8619e-03, -2.6223e-03, -1.0924e-02,  3.0581e-04,\n",
       "         -7.2345e-03,  9.4363e-03, -2.3889e-02, -7.2054e-03, -1.0029e-02],\n",
       "        [ 2.7415e-02, -6.9346e-04, -1.4137e-02, -4.0292e-05,  1.7730e-02,\n",
       "          1.1420e-02,  2.9342e-03, -1.5428e-02,  9.0474e-03, -8.7754e-03,\n",
       "          1.0579e-02,  3.0615e-02, -2.1497e-02,  2.1536e-04, -2.2380e-02,\n",
       "          5.9956e-03, -2.6935e-02,  4.2404e-03,  5.1335e-03, -1.8685e-03],\n",
       "        [ 5.7628e-03, -2.1533e-04, -3.8835e-03, -3.4483e-03,  9.0302e-03,\n",
       "          2.0890e-02,  1.2334e-02,  3.5524e-03, -4.4642e-03,  9.1585e-03,\n",
       "         -1.1557e-02,  6.4052e-03, -1.7112e-02, -2.5993e-02,  5.5869e-03,\n",
       "          3.0948e-02,  7.7756e-03, -6.3311e-02, -1.4401e-02, -7.1595e-03],\n",
       "        [ 2.5138e-02, -6.1307e-03,  1.8512e-02, -3.9411e-03, -5.5552e-03,\n",
       "         -1.0113e-02, -1.2409e-02, -1.4101e-02,  5.4319e-03, -2.2460e-02,\n",
       "          2.2427e-02, -1.5698e-02,  1.6910e-02, -1.3260e-02, -5.2717e-03,\n",
       "         -1.0123e-02, -2.7678e-02,  2.9454e-02,  1.9042e-02,  1.6729e-02],\n",
       "        [ 1.9520e-04,  2.4171e-04, -4.4321e-04,  5.8897e-03,  8.0055e-03,\n",
       "         -3.0499e-03, -3.2779e-03,  5.3084e-03,  3.6447e-03,  8.1607e-03,\n",
       "         -4.9406e-03,  1.2878e-02, -1.1800e-02,  1.3209e-02, -7.0312e-03,\n",
       "          5.0135e-03,  1.7718e-03,  7.6934e-03, -1.3487e-04, -2.0637e-03],\n",
       "        [-3.2627e-02, -3.1330e-03,  1.2981e-02, -3.2287e-03, -2.5471e-02,\n",
       "         -2.7949e-02, -1.5785e-02, -1.5454e-03, -9.0460e-03, -1.0557e-02,\n",
       "          1.5691e-02, -4.4851e-02,  4.7263e-02, -1.4274e-03,  1.0813e-02,\n",
       "         -5.0067e-02,  7.2339e-03,  5.3835e-02,  1.8892e-02,  1.3239e-02],\n",
       "        [-4.2891e-02, -1.4017e-03,  2.2579e-02,  1.4344e-02, -8.2753e-03,\n",
       "         -3.4300e-02, -2.1241e-02,  2.9683e-02, -4.2979e-03,  2.6206e-02,\n",
       "         -1.5726e-02, -2.0836e-02,  1.3791e-02,  3.0261e-02,  9.0171e-03,\n",
       "         -1.5861e-02,  3.5495e-02,  4.0394e-02,  5.0953e-03,  4.3703e-03],\n",
       "        [ 4.4051e-02,  4.3271e-03, -3.1188e-02,  5.5493e-03,  3.8325e-02,\n",
       "          3.0748e-02,  1.6033e-02, -1.0936e-02,  1.6767e-02,  4.4933e-03,\n",
       "         -5.9175e-03,  7.2972e-02, -6.1555e-02,  1.7004e-02, -3.2730e-02,\n",
       "          3.9455e-02, -2.6842e-02, -2.6188e-02, -1.1865e-02, -1.6526e-02],\n",
       "        [-7.2059e-02, -9.3106e-04, -6.6318e-03,  2.2612e-03, -8.0521e-03,\n",
       "         -1.2675e-02, -4.3492e-03,  1.9419e-02, -2.1573e-02,  2.7964e-02,\n",
       "         -1.3400e-02, -2.8378e-02,  2.0174e-02, -1.0948e-02,  1.2867e-02,\n",
       "         -3.0538e-02,  4.7222e-02, -9.7213e-03, -1.5547e-03, -6.3250e-03],\n",
       "        [ 9.6161e-03, -3.1724e-03,  3.6120e-02,  1.5662e-03, -1.5281e-02,\n",
       "         -1.6074e-02, -1.1761e-02,  1.1403e-02,  1.9396e-03, -3.1939e-03,\n",
       "         -2.4452e-03, -2.9613e-02,  1.7861e-02, -2.7587e-04,  1.7932e-02,\n",
       "          1.1534e-02,  4.3506e-03,  7.5371e-03,  2.7519e-03,  1.3503e-02],\n",
       "        [ 4.0308e-02,  1.0488e-02, -2.8717e-02, -7.7294e-03, -4.5012e-03,\n",
       "          1.9076e-02,  2.0596e-02, -2.6118e-02,  1.4242e-02, -3.1119e-02,\n",
       "          1.1993e-02,  3.1900e-02, -8.1600e-03,  3.0542e-02, -7.2675e-03,\n",
       "         -3.2414e-03, -3.4415e-02,  2.4394e-02, -7.8176e-03, -8.2453e-03]],\n",
       "       grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.w_down @ model.w_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 99, Loss: 2.97719\n",
      "Step: 199, Loss: 2.95484\n",
      "Step: 299, Loss: 2.91424\n",
      "Step: 399, Loss: 2.83856\n",
      "Step: 499, Loss: 2.71799\n",
      "Step: 599, Loss: 2.56096\n",
      "Step: 699, Loss: 2.42010\n",
      "Step: 799, Loss: 2.31719\n",
      "Step: 899, Loss: 2.24325\n",
      "Step: 999, Loss: 2.18678\n",
      "Step: 1099, Loss: 2.14320\n",
      "Step: 1199, Loss: 2.10878\n",
      "Step: 1299, Loss: 2.08054\n",
      "Step: 1399, Loss: 2.05660\n",
      "Step: 1499, Loss: 2.03680\n",
      "Step: 1599, Loss: 2.01892\n",
      "Step: 1699, Loss: 2.00539\n",
      "Step: 1799, Loss: 1.99155\n",
      "Step: 1899, Loss: 1.98227\n",
      "Step: 1999, Loss: 1.97185\n",
      "Step: 2099, Loss: 1.96348\n",
      "Step: 2199, Loss: 1.95688\n",
      "Step: 2299, Loss: 1.95025\n",
      "Step: 2399, Loss: 1.94426\n",
      "Step: 2499, Loss: 1.93764\n",
      "Step: 2599, Loss: 1.93286\n",
      "Step: 2699, Loss: 1.92787\n",
      "Step: 2799, Loss: 1.92556\n",
      "Step: 2899, Loss: 1.92206\n",
      "Step: 2999, Loss: 1.91959\n",
      "Step: 3099, Loss: 1.91540\n",
      "Step: 3199, Loss: 1.91347\n",
      "Step: 3299, Loss: 1.91136\n",
      "Step: 3399, Loss: 1.91001\n",
      "Step: 3499, Loss: 1.90907\n",
      "Step: 3599, Loss: 1.90750\n",
      "Step: 3699, Loss: 1.90547\n",
      "Step: 3799, Loss: 1.90399\n",
      "Step: 3899, Loss: 1.90280\n",
      "Step: 3999, Loss: 1.90173\n",
      "Step: 4099, Loss: 1.89861\n",
      "Step: 4199, Loss: 1.89765\n",
      "Step: 4299, Loss: 1.89688\n",
      "Step: 4399, Loss: 1.89544\n",
      "Step: 4499, Loss: 1.89493\n",
      "Step: 4599, Loss: 1.89441\n",
      "Step: 4699, Loss: 1.89433\n",
      "Step: 4799, Loss: 1.89338\n",
      "Step: 4899, Loss: 1.89171\n",
      "Step: 4999, Loss: 1.89142\n"
     ]
    }
   ],
   "source": [
    "model.train(x=X,\n",
    "            labels=Y,\n",
    "            steps=5000,\n",
    "            optimizer_fn=torch.optim.SGD,\n",
    "            optimizer_args={'lr': 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4.78+6.62+1.70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.matrix_rank(model(np.eye(n_nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([14.,  4.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       "  array([9., 5., 2., 3., 1., 0., 0., 0., 0., 0.]),\n",
       "  array([9., 6., 3., 1., 0., 0., 1., 0., 0., 0.]),\n",
       "  array([10.,  6.,  3.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       "  array([9., 5., 2., 3., 1., 0., 0., 0., 0., 0.]),\n",
       "  array([11.,  1.,  4.,  2.,  0.,  0.,  0.,  1.,  1.,  0.]),\n",
       "  array([14.,  3.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]),\n",
       "  array([12.,  5.,  0.,  2.,  1.,  0.,  0.,  0.,  0.,  0.]),\n",
       "  array([11.,  4.,  1.,  3.,  0.,  0.,  0.,  1.,  0.,  0.]),\n",
       "  array([11.,  6.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.]),\n",
       "  array([14.,  2.,  3.,  0.,  0.,  0.,  1.,  0.,  0.,  0.]),\n",
       "  array([13.,  3.,  0.,  3.,  1.,  0.,  0.,  0.,  0.,  0.]),\n",
       "  array([10.,  4.,  2.,  2.,  1.,  0.,  0.,  1.,  0.,  0.]),\n",
       "  array([10.,  5.,  1.,  3.,  0.,  1.,  0.,  0.,  0.,  0.]),\n",
       "  array([8., 6., 2., 4., 0., 0., 0., 0., 0., 0.]),\n",
       "  array([11.,  2.,  4.,  2.,  1.,  0.,  0.,  0.,  0.,  0.]),\n",
       "  array([12.,  3.,  2.,  2.,  1.,  0.,  0.,  0.,  0.,  0.]),\n",
       "  array([14.,  3.,  2.,  0.,  1.,  0.,  0.,  0.,  0.,  0.]),\n",
       "  array([12.,  5.,  2.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       "  array([12.,  6.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.])],\n",
       " array([9.30688486e-06, 1.20476714e-02, 2.40860359e-02, 3.61244004e-02,\n",
       "        4.81627649e-02, 6.02011294e-02, 7.22394939e-02, 8.42778584e-02,\n",
       "        9.63162229e-02, 1.08354587e-01, 1.20392952e-01]),\n",
       " <a list of 20 Lists of Patches objects>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.abs((model(np.eye(n_nodes))-p_stars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.037179497211325865"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(normalized - p_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4654196748812593"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(model(np.eye(n_nodes)) - p_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:netgan]",
   "language": "python",
   "name": "conda-env-netgan-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
